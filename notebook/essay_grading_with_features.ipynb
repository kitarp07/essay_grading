{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhhOpTR9zrZA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertModel, BertPreTrainedModel, DistilBertTokenizer, DistilBertModel, DistilBertPreTrainedModel\n",
        "from sklearn.metrics import mean_squared_error, cohen_kappa_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoL2J5GjqcUT",
        "outputId": "eb07ecf5-5800-4cf6-cbe2-7859c6ef0d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"essay_set_8.csv\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 999
        },
        "id": "hzlMWRTQuRug",
        "outputId": "14d93f1f-dab3-4475-9d41-2667337f0b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0  essay_id  essay_set  \\\n",
              "0         12255     20716          8   \n",
              "1         12256     20717          8   \n",
              "2         12257     20718          8   \n",
              "3         12258     20719          8   \n",
              "4         12259     20721          8   \n",
              "..          ...       ...        ...   \n",
              "718       12973     21626          8   \n",
              "719       12974     21628          8   \n",
              "720       12975     21629          8   \n",
              "721       12976     21630          8   \n",
              "722       12977     21633          8   \n",
              "\n",
              "                                                 essay  rater1_domain1  \\\n",
              "0     A long time ago when I was in third grade I h...            18.0   \n",
              "1     Softball has to be one of the single most gre...            21.0   \n",
              "2     Some people like making people laugh, I love ...            15.0   \n",
              "3     \"LAUGHTER\"  @CAPS1 I hang out with my friends...            12.0   \n",
              "4    Well ima tell a story about the time i got @CA...            11.0   \n",
              "..                                                 ...             ...   \n",
              "718   In most stories mothers and daughters are eit...            17.0   \n",
              "719   I never understood the meaning laughter is th...            15.0   \n",
              "720  When you laugh, is @CAPS5 out of habit, or is ...            20.0   \n",
              "721                                 Trippin' on fen...            20.0   \n",
              "722   Many people believe that laughter can improve...            20.0   \n",
              "\n",
              "     rater2_domain1  domain1_score  rater1_trait1  rater1_trait2  \\\n",
              "0              16.0           34.0            4.0            4.0   \n",
              "1              26.0           46.0            5.0            4.0   \n",
              "2              20.0           40.0            3.0            3.0   \n",
              "3              20.0           30.0            3.0            3.0   \n",
              "4              15.0           26.0            3.0            2.0   \n",
              "..              ...            ...            ...            ...   \n",
              "718            18.0           35.0            4.0            3.0   \n",
              "719            17.0           32.0            3.0            3.0   \n",
              "720            26.0           40.0            4.0            4.0   \n",
              "721            20.0           40.0            4.0            4.0   \n",
              "722            20.0           40.0            4.0            4.0   \n",
              "\n",
              "     rater1_trait3  rater1_trait4  rater1_trait5  rater1_trait6  \\\n",
              "0              4.0            4.0            4.0            3.0   \n",
              "1              5.0            4.0            4.0            4.0   \n",
              "2              3.0            3.0            3.0            3.0   \n",
              "3              3.0            3.0            2.0            2.0   \n",
              "4              3.0            3.0            2.0            2.0   \n",
              "..             ...            ...            ...            ...   \n",
              "718            4.0            4.0            4.0            3.0   \n",
              "719            4.0            3.0            3.0            3.0   \n",
              "720            4.0            4.0            4.0            4.0   \n",
              "721            4.0            4.0            4.0            4.0   \n",
              "722            4.0            4.0            4.0            4.0   \n",
              "\n",
              "     rater2_trait1  rater2_trait2  rater2_trait3  rater2_trait4  \\\n",
              "0              3.0            4.0            4.0            4.0   \n",
              "1              6.0            5.0            6.0            6.0   \n",
              "2              4.0            4.0            5.0            4.0   \n",
              "3              4.0            4.0            4.0            4.0   \n",
              "4              3.0            3.0            3.0            3.0   \n",
              "..             ...            ...            ...            ...   \n",
              "718            4.0            4.0            4.0            4.0   \n",
              "719            4.0            3.0            4.0            4.0   \n",
              "720            6.0            5.0            5.0            5.0   \n",
              "721            4.0            4.0            4.0            4.0   \n",
              "722            4.0            4.0            4.0            4.0   \n",
              "\n",
              "     rater2_trait5  rater2_trait6  \n",
              "0              3.0            3.0  \n",
              "1              5.0            5.0  \n",
              "2              4.0            4.0  \n",
              "3              4.0            4.0  \n",
              "4              3.0            3.0  \n",
              "..             ...            ...  \n",
              "718            4.0            3.0  \n",
              "719            4.0            3.0  \n",
              "720            5.0            5.0  \n",
              "721            4.0            4.0  \n",
              "722            4.0            4.0  \n",
              "\n",
              "[723 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-799e454c-7c10-4f61-bb0a-55208cb124ba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1_domain1</th>\n",
              "      <th>rater2_domain1</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>rater1_trait1</th>\n",
              "      <th>rater1_trait2</th>\n",
              "      <th>rater1_trait3</th>\n",
              "      <th>rater1_trait4</th>\n",
              "      <th>rater1_trait5</th>\n",
              "      <th>rater1_trait6</th>\n",
              "      <th>rater2_trait1</th>\n",
              "      <th>rater2_trait2</th>\n",
              "      <th>rater2_trait3</th>\n",
              "      <th>rater2_trait4</th>\n",
              "      <th>rater2_trait5</th>\n",
              "      <th>rater2_trait6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12255</td>\n",
              "      <td>20716</td>\n",
              "      <td>8</td>\n",
              "      <td>A long time ago when I was in third grade I h...</td>\n",
              "      <td>18.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12256</td>\n",
              "      <td>20717</td>\n",
              "      <td>8</td>\n",
              "      <td>Softball has to be one of the single most gre...</td>\n",
              "      <td>21.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12257</td>\n",
              "      <td>20718</td>\n",
              "      <td>8</td>\n",
              "      <td>Some people like making people laugh, I love ...</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12258</td>\n",
              "      <td>20719</td>\n",
              "      <td>8</td>\n",
              "      <td>\"LAUGHTER\"  @CAPS1 I hang out with my friends...</td>\n",
              "      <td>12.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12259</td>\n",
              "      <td>20721</td>\n",
              "      <td>8</td>\n",
              "      <td>Well ima tell a story about the time i got @CA...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>12973</td>\n",
              "      <td>21626</td>\n",
              "      <td>8</td>\n",
              "      <td>In most stories mothers and daughters are eit...</td>\n",
              "      <td>17.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>719</th>\n",
              "      <td>12974</td>\n",
              "      <td>21628</td>\n",
              "      <td>8</td>\n",
              "      <td>I never understood the meaning laughter is th...</td>\n",
              "      <td>15.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720</th>\n",
              "      <td>12975</td>\n",
              "      <td>21629</td>\n",
              "      <td>8</td>\n",
              "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
              "      <td>20.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>721</th>\n",
              "      <td>12976</td>\n",
              "      <td>21630</td>\n",
              "      <td>8</td>\n",
              "      <td>Trippin' on fen...</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>722</th>\n",
              "      <td>12977</td>\n",
              "      <td>21633</td>\n",
              "      <td>8</td>\n",
              "      <td>Many people believe that laughter can improve...</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>723 rows × 19 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-799e454c-7c10-4f61-bb0a-55208cb124ba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-799e454c-7c10-4f61-bb0a-55208cb124ba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-799e454c-7c10-4f61-bb0a-55208cb124ba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-291fcf1c-d76a-4b88-a8d0-ba3637fc2bee\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-291fcf1c-d76a-4b88-a8d0-ba3637fc2bee')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-291fcf1c-d76a-4b88-a8d0-ba3637fc2bee button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_403861db-2c5d-420a-9cb0-7594047f0643\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_403861db-2c5d-420a-9cb0-7594047f0643 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 723,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 208,\n        \"min\": 12255,\n        \"max\": 12977,\n        \"num_unique_values\": 723,\n        \"samples\": [\n          12591,\n          12772,\n          12853\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"essay_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 262,\n        \"min\": 20716,\n        \"max\": 21633,\n        \"num_unique_values\": 723,\n        \"samples\": [\n          21135,\n          21364,\n          21468\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"essay_set\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 8,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"essay\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 723,\n        \"samples\": [\n          \" I have always tried to be a happy person, and over time I have learned that laughter is a key component to my happiness. I have succeeded in being a happy girl most of my life. Even as a baby, I hardly ever cried; I was always laughing and giggling. As I have grown up, I have tried to keep up my happy-go-lucky spirits. Sometimes this was not the case, but that is simply reality. There have been many times in my life where laughter was all that surrounded me. I rely on laughter to keep me close with my friends, and so far, this trust has always came through, and it has worked for me. I often find myself remembering that laughter and happiness is really what life is all about. When I was first born, I didn't cry. I never cried very much as a baby. My mom reminds me of this whenever I ask her about my baby years. As a young kid, I wanted to be a part of everything that surrounded me! I was always looking for laughter and exciting events; I didn't want to miss a beat! My mom would have to take drives just so I could take a nap, and even then, I would hardly ever fell asleep. For if I did, @CAPS1 forbid, I might miss a moment of laughter! If someone else was laughing, I was laughing with them. Sometimes, I had no idea what was going on, or I wondered why what they had said was so funny, but I loved the feeling laughing with other people. I am always reminded of my happy toddler years whenever I look at my baby pictures. I don't have one of those pictures where I am bawling my eyes out, like you might find in most kid's baby pictures. In every baby picture of me, I'm laughing. If I'm not laughing, then there is a wide smile spread from ear to ear! Laughter is what kept me a happy baby! As a preteen, I was still the girl who you would always see laughing and smiling. I sometimes wondered what it felt like to cry because I had never felt that type of feeling before. I was always so caught up in laughter that I never had time to think about the negative. Now, I unfortunately know the feeling of sadness and being upset, and I try incredibly hard to go back to when I didn't know these feelings. Whenever I'm feeling down, I attempt to find laughter in each thing I do. When I attempt this, I can always find laughter, and my spirits are brought back up. My friends are always a place I can go to for a pick me up. Especially @PERSON1, who is my best friend. Every time I am with her, I find myself laughing for one reason or another. @PERSON1 and I have not had the steadiest friendship, but what always brings us close again is laughter. Our fights always end when we find common ground in something funny. Usually, she is the one who finds this, and she makes me laugh. Laughter is what has kept @LOCATION1 and I so close for the past few years. If laughter didn't exist, I can assure you that we would be anything but friends right now! Not long ago, I was in the car with three of my closest friends: @LOCATION1, @CAPS2, and @PERSON2. We were all laughing and singing as loud as we could to one of our favorite songs. I looked over to my friends and saw all of their smiling faces, and I found myself smiling too. I realized then, that laughter is truly what life is all about. Laughter is what has kept me close to all of my peers throughout my life. When I was little, I was gravitated towards those who I had the most fun with, and who I laughed with the most. As I've grown older, that same thinking is still there; I want to be with the people that make me laugh. The older I have gotten, the more I've learned about what I need in a friend. My main criteria is someone who can make me laugh. If I'm with someone with a dry sense of humor, and who doesn't talk at all, then I am going to go find someone who is laughable and hilarious!  Laughter is something that I am extremely thankful for. It has been the key to making me happy for all fifteen years of my life! From when I was a baby, up until now, laughter is what always has been, and what always will be, what my life is all about!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater1_domain1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.1701468175553305,\n        \"min\": 5.0,\n        \"max\": 30.0,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          18.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater2_domain1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.17066888079381,\n        \"min\": 5.0,\n        \"max\": 30.0,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          16.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"domain1_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.753501579717448,\n        \"min\": 10.0,\n        \"max\": 60.0,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          38.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater1_trait1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7116019402260446,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater1_trait2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.696687685650049,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater1_trait3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6417193278552242,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater1_trait4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6389010422789978,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater1_trait5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7177456580098531,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater1_trait6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6999795565867009,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater2_trait1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7287274555541959,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater2_trait2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7176896061297644,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater2_trait3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6860308072715461,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater2_trait4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.622283639758566,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater2_trait5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6894013566598195,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater2_trait6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6932558483144372,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install language_tool_python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS2P14faAllk",
        "outputId": "6f550121-efa6-44bc-c572-288d17598ced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: language_tool_python in /usr/local/lib/python3.10/dist-packages (2.8.1)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from language_tool_python) (24.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from language_tool_python) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from language_tool_python) (4.66.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from language_tool_python) (0.44.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->language_tool_python) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->language_tool_python) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->language_tool_python) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->language_tool_python) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import language_tool_python\n",
        "tool = language_tool_python.LanguageTool('en-US')"
      ],
      "metadata": {
        "id": "9x0660BWAit5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_grammar_spelling_errors(text):\n",
        "    matches = tool.check(text)\n",
        "    return matches\n",
        "\n",
        "# text = \"I am not a patience person, like I can’t sit in a sit for more than five minutes, but there was one time I was patience and i bet very alse was to that right riding a bike where out training wheels. When I was five learned how to ride a bike I just keeped falling of at one piont my bike  flip and I allmost broke my jaw but i didn’t. Finally after @NUM1 weeks of onstint falling I rode for @NUM2 minutes without falling and finally learn how to riken a bike.\"\n",
        "# matches = get_grammar_spelling_errors(text)\n",
        "# print(f\"Grammar errors: {len(matches)}\")\n",
        "\n",
        "# for match in matches:\n",
        "#     print(f\"Error: {match.message} at position {match.offset}\")\n"
      ],
      "metadata": {
        "id": "HYX6HeFVB827"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load Spacy model and a sentence embedding model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "embedder = pipeline(\"feature-extraction\", model=\"bert-base-uncased\", tokenizer=\"bert-base-uncased\", truncation= True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "\n",
        "\n",
        "def get_sentence_embeddings(text, max_length=512):\n",
        "    # Tokenize the text into sentences\n",
        "    doc = nlp(text)\n",
        "    sentences = [sent.text for sent in doc.sents]\n",
        "\n",
        "    embeddings = []\n",
        "    for sentence in sentences:\n",
        "        tokens = tokenizer(sentence, return_tensors='pt', truncation=True, max_length=max_length)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**tokens)\n",
        "            sentence_embedding = outputs.last_hidden_state.mean(dim=1).numpy().flatten()\n",
        "        embeddings.append(sentence_embedding)\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "def sentence_similarity(text):\n",
        "    # Get embeddings for the text\n",
        "    embeddings = get_sentence_embeddings(text)\n",
        "\n",
        "    # Calculate cosine similarity between consecutive sentence embeddings\n",
        "    similarities = [cosine_similarity([embeddings[i]], [embeddings[i+1]])[0, 0] for i in range(len(embeddings) - 1)]\n",
        "    avg_similarity = np.mean(similarities) if similarities else 0\n",
        "\n",
        "    return avg_similarity\n",
        "\n",
        "\n",
        "\n",
        "# def sentence_similarity(text):\n",
        "#     # Tokenize the text into sentences\n",
        "#     doc = nlp(text)\n",
        "#     sentences = [sent.text for sent in doc.sents]\n",
        "\n",
        "#     # Generate embeddings for each sentence\n",
        "#     embeddings = [np.mean(embedder(sentence)[0], axis=0) for sentence in sentences]\n",
        "\n",
        "#     # Calculate cosine similarity between consecutive sentences\n",
        "#     similarities = [cosine_similarity([embeddings[i]], [embeddings[i+1]])[0, 0] for i in range(len(embeddings) - 1)]\n",
        "#     avg_similarity = np.mean(similarities) if similarities else 0\n",
        "\n",
        "\n",
        "#     return avg_similarity\n",
        "\n",
        "# Example essay\n",
        "# essay = \"The climate is changing rapidly. This change is mainly due to human activities. It affects weather patterns and ecosystems worldwide.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kAesPaNwjwq",
        "outputId": "94b6772b-c5e7-4f1f-ecda-5055f9b7764b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "essay = df[\"essay\"][2]\n",
        "# Extract coherence features\n",
        "features = sentence_similarity(essay)\n",
        "print(\"Adjencent sentence similarity:\", features)"
      ],
      "metadata": {
        "id": "rPN7wGkK8qCY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aab0e1f5-0b93-4385-bb4e-dd013846531e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjencent sentence similarity: 0.71224356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "# Load the spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_features(text):\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Lexical Cohesion Features\n",
        "    tokens = [token.text.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
        "    lemmas = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
        "    lemma_counts = Counter(lemmas)\n",
        "\n",
        "    lexical_repetition_ratio = sum(count for count in lemma_counts.values() if count > 1) / len(tokens) if tokens else 0\n",
        "    unique_lemmas_count = len(lemma_counts)\n",
        "\n",
        "    # Pronoun Usage\n",
        "    pronouns = [token.text.lower() for token in doc if token.pos_ == \"PRON\"]\n",
        "    pronoun_count = len(pronouns)\n",
        "\n",
        "    # Conjunctions and Connectives\n",
        "    conjunctions = {\"and\", \"or\", \"but\", \"because\", \"although\", \"however\", \"therefore\", \"moreover\", \"thus\", \"furthermore\", \"then\"}\n",
        "    conjunction_count = sum(1 for token in doc if token.text.lower() in conjunctions)\n",
        "\n",
        "    # Entity Coherence\n",
        "    entities = [ent.text.lower() for ent in doc.ents]\n",
        "    entity_counts = Counter(entities)\n",
        "    entity_repetition_count = sum(count for count in entity_counts.values() if count > 1)\n",
        "\n",
        "    # Sentence-Level Features\n",
        "    sentence_lengths = [len(sent) for sent in doc.sents]\n",
        "    avg_sentence_length = np.mean(sentence_lengths) if sentence_lengths else 0\n",
        "    sentence_length_std = np.std(sentence_lengths) if sentence_lengths else 0\n",
        "\n",
        "    # Paragraph-Level Features\n",
        "    paragraphs = text.split('\\n\\n')\n",
        "    paragraph_lengths = [len(p.split()) for p in paragraphs]\n",
        "    avg_paragraph_length = np.mean(paragraph_lengths) if paragraph_lengths else 0\n",
        "\n",
        "    features = {\n",
        "        \"lexical_repetition_ratio\": lexical_repetition_ratio,\n",
        "        \"unique_lemmas_count\": unique_lemmas_count,\n",
        "        \"pronoun_count\": pronoun_count,\n",
        "        \"conjunction_count\": conjunction_count,\n",
        "        \"entity_repetition_count\": entity_repetition_count,\n",
        "        \"avg_sentence_length\": avg_sentence_length,\n",
        "        \"sentence_length_std\": sentence_length_std,\n",
        "        \"avg_paragraph_length\": avg_paragraph_length\n",
        "    }\n",
        "\n",
        "    return features\n",
        "\n"
      ],
      "metadata": {
        "id": "LHpIco8h9tf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example essay\n",
        "essay = \"\"\"\n",
        "The rapid changes in climate are primarily caused by human activities.\n",
        "This is evident in the increased carbon emissions from vehicles and industries.\n",
        "Furthermore, deforestation plays a significant role in disrupting ecological balance.\n",
        "Therefore, it is crucial to adopt sustainable practices to mitigate these impacts.\n",
        "\"\"\"\n",
        "\n",
        "# Extract features\n",
        "features = extract_features(essay)\n",
        "print(\"Handcrafted Features:\", features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhphvP0q9vpp",
        "outputId": "2ef3a17d-20f0-4f90-ec7d-c3da915b1e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Handcrafted Features: {'lexical_repetition_ratio': 0.15625, 'unique_lemmas_count': 28, 'pronoun_count': 2, 'conjunction_count': 3, 'entity_repetition_count': 0, 'avg_sentence_length': 14.0, 'sentence_length_std': 0.7071067811865476, 'avg_paragraph_length': 45.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "# Download NLTK resources (if not already downloaded)\n",
        "nltk.download('punkt')\n",
        "\n",
        "def count_discourse_connectives(essay):\n",
        "    \"\"\"\n",
        "    Count the occurrences of discourse connectives in a given essay.\n",
        "\n",
        "    Parameters:\n",
        "    - essay (str): The text of the essay.\n",
        "    - discourse_connectives (list): List of discourse connectives to look for.\n",
        "\n",
        "    Returns:\n",
        "    - connective_counts (Counter): A Counter object with the count of each connective.\n",
        "    - total_count (int): Total count of discourse connectives found.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define discourse connectives\n",
        "    discourse_connectives = [\n",
        "        \"furthermore\", \"moreover\", \"in addition\", \"besides\", \"also\", \"similarly\",\n",
        "        \"as well as\", \"equally important\", \"not only\", \"but also\", \"however\",\n",
        "        \"although\", \"though\", \"on the other hand\", \"nevertheless\", \"nonetheless\",\n",
        "        \"whereas\", \"while\", \"despite\", \"in contrast\", \"alternatively\", \"therefore\",\n",
        "        \"consequently\", \"thus\", \"as a result\", \"because\", \"since\", \"due to\",\n",
        "        \"hence\", \"if\", \"unless\", \"provided that\", \"in case\", \"as long as\",\n",
        "        \"on the condition that\", \"then\", \"subsequently\", \"earlier\", \"later\",\n",
        "        \"meanwhile\", \"before\", \"after\", \"during\", \"once\", \"until\", \"when\",\n",
        "        \"indeed\", \"in fact\", \"certainly\", \"especially\", \"particularly\",\n",
        "        \"importantly\", \"in conclusion\", \"to sum up\", \"overall\", \"in summary\",\n",
        "        \"thus\", \"consequently\", \"ultimately\", \"for example\", \"for instance\",\n",
        "        \"such as\", \"to illustrate\", \"namely\", \"in other words\", \"that is to say\",\n",
        "        \"to put it another way\"\n",
        "    ]\n",
        "\n",
        "    # Tokenize the essay\n",
        "    tokens = word_tokenize(essay.lower())\n",
        "\n",
        "    # Count occurrences of discourse connectives\n",
        "    connective_counts = Counter(token for token in tokens if token in discourse_connectives)\n",
        "    total_count = sum(connective_counts.values())\n",
        "\n",
        "    return connective_counts, total_count\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zdl1CiSRALyA",
        "outputId": "7b5fd173-e612-4f34-fe9e-541f566f2bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "essay = df[\"essay\"][2]\n",
        "connective_counts, total_count = count_discourse_connectives(essay)\n",
        "\n",
        "print(\"Discourse Connective Counts:\", connective_counts)\n",
        "print(\"Total Count:\", total_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq1JMIHxbLPP",
        "outputId": "6e70d06c-2e2e-477d-896f-a7a0124401c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discourse Connective Counts: Counter({'while': 1, 'since': 1, 'also': 1})\n",
            "Total Count: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "# Ensure required NLTK resources are downloaded\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def calculate_vocabulary_richness(text):\n",
        "    \"\"\"\n",
        "    Calculate the Type-Token Ratio (TTR) to measure vocabulary richness in a given text.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): The input text for which to calculate vocabulary richness.\n",
        "\n",
        "    Returns:\n",
        "    float: The Type-Token Ratio (TTR) representing the vocabulary richness.\n",
        "    \"\"\"\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text.lower())\n",
        "\n",
        "    # Remove punctuation and stopwords\n",
        "    tokens = [word for word in tokens if word.isalpha()]\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Calculate the number of unique words and total words\n",
        "    unique_words = set(tokens)\n",
        "    total_words = len(tokens)\n",
        "    unique_word_count = len(unique_words)\n",
        "\n",
        "    # Calculate Type-Token Ratio (TTR)\n",
        "    if total_words > 0:\n",
        "        ttr = unique_word_count / total_words\n",
        "    else:\n",
        "        ttr = 0.0\n",
        "\n",
        "    return ttr\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbi7RsdxBBho",
        "outputId": "0ed17705-e814-4271-c933-6e1bb119d690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "text = df[\"essay\"][4]\n",
        "vocabulary_richness = calculate_vocabulary_richness(text)\n",
        "print(f\"Type-Token Ratio (TTR): {vocabulary_richness:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4UqzMOwBOv6",
        "outputId": "bd53d860-58e2-4f3f-8986-0a9e764a9d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type-Token Ratio (TTR): 0.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# def get_embedding(text, model, tokenizer):\n",
        "#     inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
        "#     outputs = model(**inputs)\n",
        "#     return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "\n",
        "# def calculate_semantic_relevance(prompt, essay):\n",
        "#     prompt_embedding = get_embedding(prompt, model, tokenizer)\n",
        "#     essay_embedding = get_embedding(essay, model, tokenizer)\n",
        "\n",
        "#     similarity = cosine_similarity(prompt_embedding, essay_embedding)\n",
        "#     return similarity[0, 0]\n",
        "\n",
        "\n",
        "def get_embedding(text, model, tokenizer):\n",
        "    # Tokenize text\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=False, padding=False)\n",
        "    input_ids = inputs['input_ids'].squeeze()\n",
        "    attention_mask = inputs['attention_mask'].squeeze()\n",
        "\n",
        "    # Process text in chunks\n",
        "    chunk_size = 512\n",
        "    embeddings = []\n",
        "    for i in range(0, len(input_ids), chunk_size):\n",
        "        chunk_ids = input_ids[i:i + chunk_size].unsqueeze(0)\n",
        "        chunk_attention_mask = attention_mask[i:i + chunk_size].unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids=chunk_ids, attention_mask=chunk_attention_mask)\n",
        "        chunk_embedding = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "        embeddings.append(chunk_embedding)\n",
        "\n",
        "    # Aggregate chunk embeddings\n",
        "    aggregated_embedding = np.mean(np.vstack(embeddings), axis=0)\n",
        "    return aggregated_embedding\n",
        "\n",
        "def calculate_semantic_relevance(prompt, essay):\n",
        "    prompt_embedding = get_embedding(prompt, model, tokenizer)\n",
        "    essay_embedding = get_embedding(essay, model, tokenizer)\n",
        "\n",
        "    prompt_embedding = prompt_embedding.reshape(1, -1)\n",
        "    essay_embedding = essay_embedding.reshape(1, -1)\n",
        "\n",
        "    similarity = cosine_similarity(prompt_embedding, essay_embedding)\n",
        "    return similarity[0, 0]\n"
      ],
      "metadata": {
        "id": "cXH9DyNPCSqY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aa73a69-6d0f-4d81-fd43-7326773a6b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample prompt and essay\n",
        "prompt = '''Write about patience. Being patient means that you are understanding and tolerant. A patient person experience difficulties without complaining.\n",
        "Do only one of the following: write a story about a time when you were patient OR write a story about a time when someone you know was patient OR write a story in your own way about patience.\n",
        "'''\n",
        "essay = df[\"essay\"][1]\n",
        "\n",
        "# Calculate semantic relevance\n",
        "score = calculate_semantic_relevance(prompt_8, essay)\n",
        "print(f\"Semantic Relevance Score: {score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P368ITc9CU9f",
        "outputId": "1e1707ed-395b-482e-c56f-0d0631e643ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semantic Relevance Score: 0.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install textstat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOM4-rRHajgv",
        "outputId": "4594748f-1a35-4706-c946-b54af204fff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textstat\n",
            "  Downloading textstat-0.7.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.16.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from textstat) (71.0.4)\n",
            "Downloading textstat-0.7.4-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyphen-0.16.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.16.0 textstat-0.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textstat\n",
        "text = df[\"essay\"][2]\n",
        "\n",
        "# Calculate readability scores\n",
        "print(\"Flesch Reading Ease:\", textstat.flesch_reading_ease(text))\n",
        "print(\"Flesch-Kincaid Grade Level:\", textstat.flesch_kincaid_grade(text))\n",
        "print(\"Gunning Fog Index:\", textstat.gunning_fog(text))\n",
        "print(\"SMOG Index:\", textstat.smog_index(text))\n",
        "print(\"Automated Readability Index:\", textstat.automated_readability_index(text))\n",
        "print(\"Coleman-Liau Index:\", textstat.coleman_liau_index(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uZPWZaOackB",
        "outputId": "bb160b54-a0d0-47f7-ffcb-02c6ef58c283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flesch Reading Ease: 67.28\n",
            "Flesch-Kincaid Grade Level: 9.0\n",
            "Gunning Fog Index: 10.97\n",
            "SMOG Index: 11.0\n",
            "Automated Readability Index: 10.9\n",
            "Coleman-Liau Index: 9.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_all_features(prompt,essay):\n",
        "  num_grammatical_errors = len(get_grammar_spelling_errors(essay))\n",
        "  adjacent_sentence_similarity = sentence_similarity(essay)\n",
        "  features = extract_features(essay)\n",
        "  connective_counts, total_count = count_discourse_connectives(essay)\n",
        "  vocabulary_richness = calculate_vocabulary_richness(essay)\n",
        "  semantic_relevance = calculate_semantic_relevance(prompt, essay)\n",
        "  #readability scores\n",
        "  flesch_reading_ease = textstat.flesch_reading_ease(essay)\n",
        "  flesch_kincaid_grade = textstat.flesch_kincaid_grade(essay)\n",
        "  gunning_fog_index = textstat.gunning_fog(essay)\n",
        "  smog_index = textstat.smog_index(essay)\n",
        "  automated_readability_index = textstat.automated_readability_index(essay)\n",
        "  coleman_liau_index = textstat.coleman_liau_index(essay)\n",
        "\n",
        "  return {\n",
        "      \"num_grammatical_errors\": num_grammatical_errors,\n",
        "      \"adjacent_sentence_similarity\": adjacent_sentence_similarity,\n",
        "      \"lexical_repetition_ratio\": features[\"lexical_repetition_ratio\"],\n",
        "      \"unique_lemmas_count\": features[\"unique_lemmas_count\"],\n",
        "      \"pronoun_count\": features[\"pronoun_count\"],\n",
        "      \"avg_sentence_length\": features[\"avg_sentence_length\"],\n",
        "      \"sentence_length_std\": features[\"sentence_length_std\"],\n",
        "      \"discourse_connective_count\": total_count,\n",
        "      \"vocabulary_richness\": vocabulary_richness,\n",
        "      \"semantic_relevance\": semantic_relevance,\n",
        "      \"flesch_reading_ease\": flesch_reading_ease,\n",
        "      \"flesch_kincaid_grade\": flesch_kincaid_grade,\n",
        "      \"gunning_fog_index\": gunning_fog_index,\n",
        "      \"smog_index\": smog_index,\n",
        "      \"automated_readability_index\": automated_readability_index,\n",
        "      \"coleman_liau_index\": coleman_liau_index\n",
        "  }\n"
      ],
      "metadata": {
        "id": "304FbIB-e72M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_all_features(prompt_6, df[\"essay\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kWxW4sd0Iaq",
        "outputId": "1f798337-89e1-4776-8558-a711e401e3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_grammatical_errors': 3,\n",
              " 'adjacent_sentence_similarity': 0.6585304,\n",
              " 'lexical_repetition_ratio': 0.21153846153846154,\n",
              " 'unique_lemmas_count': 45,\n",
              " 'pronoun_count': 6,\n",
              " 'avg_sentence_length': 19.0,\n",
              " 'sentence_length_std': 4.47213595499958,\n",
              " 'discourse_connective_count': 3,\n",
              " 'vocabulary_richness': 0.8688524590163934,\n",
              " 'semantic_relevance': 0.7863396,\n",
              " 'flesch_reading_ease': 59.33,\n",
              " 'flesch_kincaid_grade': 10.0,\n",
              " 'gunning_fog_index': 10.74,\n",
              " 'smog_index': 11.5,\n",
              " 'automated_readability_index': 10.9,\n",
              " 'coleman_liau_index': 9.4}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_1 = '''More and more people use computers, but not everyone agrees that this benefits society. Those who support advances in technology believe that computers have a positive effect on people. They teach hand-eye coordination, give people the ability to learn about faraway places and people, and even allow people to talk online with other people. Others have different ideas. Some experts are concerned that people are spending too much time on their computers and less time exercising, enjoying nature, and interacting with family and friends.\n",
        "Write a letter to your local newspaper in which you state your opinion on the effects computers have on people. Persuade the readers to agree with you.'''\n",
        "\n",
        "prompt_2 = ''' \"All of us can think of a book that we hope none of our children or any other children have taken off the shelf. But if I have the right to remove that book from the shelf -- that work I abhor -- then you also have exactly the same right and so does everyone else. And then we have no books left on the shelf for any of us.\" --Katherine Paterson, Author\n",
        "Write a persuasive essay to a newspaper reflecting your vies on censorship in libraries. Do you believe that certain materials, such as books, music, movies, magazines, etc., should be removed from the shelves if they are found offensive? Support your position with convincing arguments from your own experience, observations, and/or reading.'''\n",
        "\n",
        "#source_essay\n",
        "prompt_3 = '''Write a response that explains how the features of the setting affect the cyclist. In your response, include examples from the essay that support your conclusion.'''\n",
        "\n",
        "#source_essay\n",
        "prompt_4 = ''' Read the last paragraph of the story. When they come back, Saeng vowed silently to herself, in the spring, when the snows melt and the geese return and this hibiscus is budding, then I will take that test again. Write a response that explains why the author concludes the story with this paragraph. In your response, include details and examples from the story that support your ideas.'''\n",
        "\n",
        "#source_essay\n",
        "prompt_5 = '''Describe the mood created by the author in the memoir. Support your answer with relevant and specific information from the memoir.'''\n",
        "\n",
        "##source_essay\n",
        "prompt_6 = '''Based on the excerpt, describe the obstacles the builders of the Empire State Building faced in attempting to allow dirigibles to dock there. Support your answer with relevant and specific information from the excerpt.'''\n",
        "\n",
        "prompt_7 = '''Write about patience. Being patient means that you are understanding and tolerant. A patient person experience difficulties without complaining.\n",
        "Do only one of the following: write a story about a time when you were patient OR write a story about a time when someone you know was patient OR write a story in your own way about patience.'''\n",
        "\n",
        "prompt_8 = '''We all understand the benefits of laughter. For example, someone once said, “Laughter is the shortest distance between two people.” Many other people believe that laughter is an important part of any relationship. Tell a true story in which laughter was one element or part. '''\n"
      ],
      "metadata": {
        "id": "zVEFCX2riWyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 999
        },
        "id": "La4-E7I9OfQL",
        "outputId": "ee4a98a4-842b-423b-c472-1780662a3ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0  essay_id  essay_set  \\\n",
              "0         12255     20716          8   \n",
              "1         12256     20717          8   \n",
              "2         12257     20718          8   \n",
              "3         12258     20719          8   \n",
              "4         12259     20721          8   \n",
              "..          ...       ...        ...   \n",
              "718       12973     21626          8   \n",
              "719       12974     21628          8   \n",
              "720       12975     21629          8   \n",
              "721       12976     21630          8   \n",
              "722       12977     21633          8   \n",
              "\n",
              "                                                 essay  rater1_domain1  \\\n",
              "0     A long time ago when I was in third grade I h...            18.0   \n",
              "1     Softball has to be one of the single most gre...            21.0   \n",
              "2     Some people like making people laugh, I love ...            15.0   \n",
              "3     \"LAUGHTER\"  @CAPS1 I hang out with my friends...            12.0   \n",
              "4    Well ima tell a story about the time i got @CA...            11.0   \n",
              "..                                                 ...             ...   \n",
              "718   In most stories mothers and daughters are eit...            17.0   \n",
              "719   I never understood the meaning laughter is th...            15.0   \n",
              "720  When you laugh, is @CAPS5 out of habit, or is ...            20.0   \n",
              "721                                 Trippin' on fen...            20.0   \n",
              "722   Many people believe that laughter can improve...            20.0   \n",
              "\n",
              "     rater2_domain1  domain1_score  rater1_trait1  rater1_trait2  \\\n",
              "0              16.0           34.0            4.0            4.0   \n",
              "1              26.0           46.0            5.0            4.0   \n",
              "2              20.0           40.0            3.0            3.0   \n",
              "3              20.0           30.0            3.0            3.0   \n",
              "4              15.0           26.0            3.0            2.0   \n",
              "..              ...            ...            ...            ...   \n",
              "718            18.0           35.0            4.0            3.0   \n",
              "719            17.0           32.0            3.0            3.0   \n",
              "720            26.0           40.0            4.0            4.0   \n",
              "721            20.0           40.0            4.0            4.0   \n",
              "722            20.0           40.0            4.0            4.0   \n",
              "\n",
              "     rater1_trait3  rater1_trait4  rater1_trait5  rater1_trait6  \\\n",
              "0              4.0            4.0            4.0            3.0   \n",
              "1              5.0            4.0            4.0            4.0   \n",
              "2              3.0            3.0            3.0            3.0   \n",
              "3              3.0            3.0            2.0            2.0   \n",
              "4              3.0            3.0            2.0            2.0   \n",
              "..             ...            ...            ...            ...   \n",
              "718            4.0            4.0            4.0            3.0   \n",
              "719            4.0            3.0            3.0            3.0   \n",
              "720            4.0            4.0            4.0            4.0   \n",
              "721            4.0            4.0            4.0            4.0   \n",
              "722            4.0            4.0            4.0            4.0   \n",
              "\n",
              "     rater2_trait1  rater2_trait2  rater2_trait3  rater2_trait4  \\\n",
              "0              3.0            4.0            4.0            4.0   \n",
              "1              6.0            5.0            6.0            6.0   \n",
              "2              4.0            4.0            5.0            4.0   \n",
              "3              4.0            4.0            4.0            4.0   \n",
              "4              3.0            3.0            3.0            3.0   \n",
              "..             ...            ...            ...            ...   \n",
              "718            4.0            4.0            4.0            4.0   \n",
              "719            4.0            3.0            4.0            4.0   \n",
              "720            6.0            5.0            5.0            5.0   \n",
              "721            4.0            4.0            4.0            4.0   \n",
              "722            4.0            4.0            4.0            4.0   \n",
              "\n",
              "     rater2_trait5  rater2_trait6  \n",
              "0              3.0            3.0  \n",
              "1              5.0            5.0  \n",
              "2              4.0            4.0  \n",
              "3              4.0            4.0  \n",
              "4              3.0            3.0  \n",
              "..             ...            ...  \n",
              "718            4.0            3.0  \n",
              "719            4.0            3.0  \n",
              "720            5.0            5.0  \n",
              "721            4.0            4.0  \n",
              "722            4.0            4.0  \n",
              "\n",
              "[723 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cd8c038-ae7e-463a-abbe-26254d498827\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1_domain1</th>\n",
              "      <th>rater2_domain1</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>rater1_trait1</th>\n",
              "      <th>rater1_trait2</th>\n",
              "      <th>rater1_trait3</th>\n",
              "      <th>rater1_trait4</th>\n",
              "      <th>rater1_trait5</th>\n",
              "      <th>rater1_trait6</th>\n",
              "      <th>rater2_trait1</th>\n",
              "      <th>rater2_trait2</th>\n",
              "      <th>rater2_trait3</th>\n",
              "      <th>rater2_trait4</th>\n",
              "      <th>rater2_trait5</th>\n",
              "      <th>rater2_trait6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12255</td>\n",
              "      <td>20716</td>\n",
              "      <td>8</td>\n",
              "      <td>A long time ago when I was in third grade I h...</td>\n",
              "      <td>18.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12256</td>\n",
              "      <td>20717</td>\n",
              "      <td>8</td>\n",
              "      <td>Softball has to be one of the single most gre...</td>\n",
              "      <td>21.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12257</td>\n",
              "      <td>20718</td>\n",
              "      <td>8</td>\n",
              "      <td>Some people like making people laugh, I love ...</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12258</td>\n",
              "      <td>20719</td>\n",
              "      <td>8</td>\n",
              "      <td>\"LAUGHTER\"  @CAPS1 I hang out with my friends...</td>\n",
              "      <td>12.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12259</td>\n",
              "      <td>20721</td>\n",
              "      <td>8</td>\n",
              "      <td>Well ima tell a story about the time i got @CA...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>12973</td>\n",
              "      <td>21626</td>\n",
              "      <td>8</td>\n",
              "      <td>In most stories mothers and daughters are eit...</td>\n",
              "      <td>17.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>719</th>\n",
              "      <td>12974</td>\n",
              "      <td>21628</td>\n",
              "      <td>8</td>\n",
              "      <td>I never understood the meaning laughter is th...</td>\n",
              "      <td>15.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720</th>\n",
              "      <td>12975</td>\n",
              "      <td>21629</td>\n",
              "      <td>8</td>\n",
              "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
              "      <td>20.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>721</th>\n",
              "      <td>12976</td>\n",
              "      <td>21630</td>\n",
              "      <td>8</td>\n",
              "      <td>Trippin' on fen...</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>722</th>\n",
              "      <td>12977</td>\n",
              "      <td>21633</td>\n",
              "      <td>8</td>\n",
              "      <td>Many people believe that laughter can improve...</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>723 rows × 19 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cd8c038-ae7e-463a-abbe-26254d498827')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3cd8c038-ae7e-463a-abbe-26254d498827 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3cd8c038-ae7e-463a-abbe-26254d498827');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4a515a96-2614-44bb-9e67-f381c14f5eaa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a515a96-2614-44bb-9e67-f381c14f5eaa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4a515a96-2614-44bb-9e67-f381c14f5eaa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_38b827b9-c1f4-4810-a57b-7bf9fba84b35\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_38b827b9-c1f4-4810-a57b-7bf9fba84b35 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 723,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 208,\n        \"min\": 12255,\n        \"max\": 12977,\n        \"num_unique_values\": 723,\n        \"samples\": [\n          12591,\n          12772,\n          12853\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"essay_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 262,\n        \"min\": 20716,\n        \"max\": 21633,\n        \"num_unique_values\": 723,\n        \"samples\": [\n          21135,\n          21364,\n          21468\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"essay_set\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 8,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"essay\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 723,\n        \"samples\": [\n          \" I have always tried to be a happy person, and over time I have learned that laughter is a key component to my happiness. I have succeeded in being a happy girl most of my life. Even as a baby, I hardly ever cried; I was always laughing and giggling. As I have grown up, I have tried to keep up my happy-go-lucky spirits. Sometimes this was not the case, but that is simply reality. There have been many times in my life where laughter was all that surrounded me. I rely on laughter to keep me close with my friends, and so far, this trust has always came through, and it has worked for me. I often find myself remembering that laughter and happiness is really what life is all about. When I was first born, I didn't cry. I never cried very much as a baby. My mom reminds me of this whenever I ask her about my baby years. As a young kid, I wanted to be a part of everything that surrounded me! I was always looking for laughter and exciting events; I didn't want to miss a beat! My mom would have to take drives just so I could take a nap, and even then, I would hardly ever fell asleep. For if I did, @CAPS1 forbid, I might miss a moment of laughter! If someone else was laughing, I was laughing with them. Sometimes, I had no idea what was going on, or I wondered why what they had said was so funny, but I loved the feeling laughing with other people. I am always reminded of my happy toddler years whenever I look at my baby pictures. I don't have one of those pictures where I am bawling my eyes out, like you might find in most kid's baby pictures. In every baby picture of me, I'm laughing. If I'm not laughing, then there is a wide smile spread from ear to ear! Laughter is what kept me a happy baby! As a preteen, I was still the girl who you would always see laughing and smiling. I sometimes wondered what it felt like to cry because I had never felt that type of feeling before. I was always so caught up in laughter that I never had time to think about the negative. Now, I unfortunately know the feeling of sadness and being upset, and I try incredibly hard to go back to when I didn't know these feelings. Whenever I'm feeling down, I attempt to find laughter in each thing I do. When I attempt this, I can always find laughter, and my spirits are brought back up. My friends are always a place I can go to for a pick me up. Especially @PERSON1, who is my best friend. Every time I am with her, I find myself laughing for one reason or another. @PERSON1 and I have not had the steadiest friendship, but what always brings us close again is laughter. Our fights always end when we find common ground in something funny. Usually, she is the one who finds this, and she makes me laugh. Laughter is what has kept @LOCATION1 and I so close for the past few years. If laughter didn't exist, I can assure you that we would be anything but friends right now! Not long ago, I was in the car with three of my closest friends: @LOCATION1, @CAPS2, and @PERSON2. We were all laughing and singing as loud as we could to one of our favorite songs. I looked over to my friends and saw all of their smiling faces, and I found myself smiling too. I realized then, that laughter is truly what life is all about. Laughter is what has kept me close to all of my peers throughout my life. When I was little, I was gravitated towards those who I had the most fun with, and who I laughed with the most. As I've grown older, that same thinking is still there; I want to be with the people that make me laugh. The older I have gotten, the more I've learned about what I need in a friend. My main criteria is someone who can make me laugh. If I'm with someone with a dry sense of humor, and who doesn't talk at all, then I am going to go find someone who is laughable and hilarious!  Laughter is something that I am extremely thankful for. It has been the key to making me happy for all fifteen years of my life! From when I was a baby, up until now, laughter is what always has been, and what always will be, what my life is all about!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater1_domain1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.1701468175553305,\n        \"min\": 5.0,\n        \"max\": 30.0,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          18.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater2_domain1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.17066888079381,\n        \"min\": 5.0,\n        \"max\": 30.0,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          16.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"domain1_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.753501579717448,\n        \"min\": 10.0,\n        \"max\": 60.0,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          38.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater1_trait1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7116019402260446,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater1_trait2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.696687685650049,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater1_trait3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6417193278552242,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater1_trait4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6389010422789978,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater1_trait5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7177456580098531,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater1_trait6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6999795565867009,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater2_trait1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7287274555541959,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater2_trait2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7176896061297644,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater2_trait3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6860308072715461,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater2_trait4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.622283639758566,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater2_trait5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6894013566598195,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rater2_trait6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6932558483144372,\n        \"min\": 1.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_features = df.apply(lambda row: calculate_all_features(prompt_8, row['essay']), axis=1)\n",
        "df_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "G9uryN9khTCe",
        "outputId": "9b6454e0-1e6a-4062-b456-9d46f512b5fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      {'num_grammatical_errors': 61, 'adjacent_sente...\n",
              "1      {'num_grammatical_errors': 17, 'adjacent_sente...\n",
              "2      {'num_grammatical_errors': 21, 'adjacent_sente...\n",
              "3      {'num_grammatical_errors': 70, 'adjacent_sente...\n",
              "4      {'num_grammatical_errors': 115, 'adjacent_sent...\n",
              "                             ...                        \n",
              "718    {'num_grammatical_errors': 19, 'adjacent_sente...\n",
              "719    {'num_grammatical_errors': 44, 'adjacent_sente...\n",
              "720    {'num_grammatical_errors': 14, 'adjacent_sente...\n",
              "721    {'num_grammatical_errors': 6, 'adjacent_senten...\n",
              "722    {'num_grammatical_errors': 2, 'adjacent_senten...\n",
              "Length: 723, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'num_grammatical_errors': 61, 'adjacent_sente...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'num_grammatical_errors': 17, 'adjacent_sente...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'num_grammatical_errors': 21, 'adjacent_sente...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'num_grammatical_errors': 70, 'adjacent_sente...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'num_grammatical_errors': 115, 'adjacent_sent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>{'num_grammatical_errors': 19, 'adjacent_sente...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>719</th>\n",
              "      <td>{'num_grammatical_errors': 44, 'adjacent_sente...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720</th>\n",
              "      <td>{'num_grammatical_errors': 14, 'adjacent_sente...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>721</th>\n",
              "      <td>{'num_grammatical_errors': 6, 'adjacent_senten...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>722</th>\n",
              "      <td>{'num_grammatical_errors': 2, 'adjacent_senten...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>723 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_df = pd.json_normalize(df_features)\n",
        "\n",
        "# Merge with the original DataFrame\n",
        "df_with_features = pd.concat([df, features_df], axis=1)\n",
        "\n",
        "# View the DataFrame with new features\n",
        "df_with_features = df_with_features.drop(df_with_features.columns[0], axis=1)\n",
        "df_with_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981
        },
        "id": "lgBjKUPRkUIT",
        "outputId": "0dad63a8-0500-4151-e8c8-cfb06bf83b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     essay_id  essay_set                                              essay  \\\n",
              "0       20716          8   A long time ago when I was in third grade I h...   \n",
              "1       20717          8   Softball has to be one of the single most gre...   \n",
              "2       20718          8   Some people like making people laugh, I love ...   \n",
              "3       20719          8   \"LAUGHTER\"  @CAPS1 I hang out with my friends...   \n",
              "4       20721          8  Well ima tell a story about the time i got @CA...   \n",
              "..        ...        ...                                                ...   \n",
              "718     21626          8   In most stories mothers and daughters are eit...   \n",
              "719     21628          8   I never understood the meaning laughter is th...   \n",
              "720     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
              "721     21630          8                                 Trippin' on fen...   \n",
              "722     21633          8   Many people believe that laughter can improve...   \n",
              "\n",
              "     rater1_domain1  rater2_domain1  domain1_score  rater1_trait1  \\\n",
              "0              18.0            16.0           34.0            4.0   \n",
              "1              21.0            26.0           46.0            5.0   \n",
              "2              15.0            20.0           40.0            3.0   \n",
              "3              12.0            20.0           30.0            3.0   \n",
              "4              11.0            15.0           26.0            3.0   \n",
              "..              ...             ...            ...            ...   \n",
              "718            17.0            18.0           35.0            4.0   \n",
              "719            15.0            17.0           32.0            3.0   \n",
              "720            20.0            26.0           40.0            4.0   \n",
              "721            20.0            20.0           40.0            4.0   \n",
              "722            20.0            20.0           40.0            4.0   \n",
              "\n",
              "     rater1_trait2  rater1_trait3  rater1_trait4  ...  sentence_length_std  \\\n",
              "0              4.0            4.0            4.0  ...             9.002410   \n",
              "1              4.0            5.0            4.0  ...            11.949837   \n",
              "2              3.0            3.0            3.0  ...            11.317015   \n",
              "3              3.0            3.0            3.0  ...            17.686580   \n",
              "4              2.0            3.0            3.0  ...             9.722998   \n",
              "..             ...            ...            ...  ...                  ...   \n",
              "718            3.0            4.0            4.0  ...            17.869146   \n",
              "719            3.0            4.0            3.0  ...             9.989607   \n",
              "720            4.0            4.0            4.0  ...            17.083961   \n",
              "721            4.0            4.0            4.0  ...             8.045972   \n",
              "722            4.0            4.0            4.0  ...             6.097503   \n",
              "\n",
              "     discourse_connective_count  vocabulary_richness  semantic_relevance  \\\n",
              "0                            13             0.520505            0.707057   \n",
              "1                            16             0.635593            0.777121   \n",
              "2                            16             0.578164            0.795551   \n",
              "3                            14             0.595070            0.737897   \n",
              "4                            17             0.522388            0.625690   \n",
              "..                          ...                  ...                 ...   \n",
              "718                          19             0.627072            0.794858   \n",
              "719                           7             0.550000            0.791210   \n",
              "720                          17             0.745509            0.766729   \n",
              "721                          21             0.663793            0.819285   \n",
              "722                           9             0.707547            0.863376   \n",
              "\n",
              "     flesch_reading_ease  flesch_kincaid_grade  gunning_fog_index  smog_index  \\\n",
              "0                  88.87                   4.9               6.90         7.0   \n",
              "1                  78.93                   8.7              11.37         8.9   \n",
              "2                  74.83                   8.2               9.62         8.5   \n",
              "3                  81.46                   7.7               9.68         7.0   \n",
              "4                  88.60                   7.1               9.98         4.2   \n",
              "..                   ...                   ...                ...         ...   \n",
              "718                65.09                  12.0              13.56        10.3   \n",
              "719                91.11                   4.0               5.97         7.1   \n",
              "720                69.11                   8.3               9.46         9.7   \n",
              "721                81.83                   5.5               7.41         8.5   \n",
              "722                72.05                   7.2               8.67         9.9   \n",
              "\n",
              "     automated_readability_index  coleman_liau_index  \n",
              "0                            6.1                5.10  \n",
              "1                           10.8                6.04  \n",
              "2                            9.1                6.15  \n",
              "3                            8.3                4.65  \n",
              "4                            7.7                3.08  \n",
              "..                           ...                 ...  \n",
              "718                         14.4                7.03  \n",
              "719                          5.1                4.98  \n",
              "720                          9.9                8.18  \n",
              "721                          6.8                6.55  \n",
              "722                          7.4                7.07  \n",
              "\n",
              "[723 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c3e726a-f167-446e-be3f-72110eebfc20\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1_domain1</th>\n",
              "      <th>rater2_domain1</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>rater1_trait1</th>\n",
              "      <th>rater1_trait2</th>\n",
              "      <th>rater1_trait3</th>\n",
              "      <th>rater1_trait4</th>\n",
              "      <th>...</th>\n",
              "      <th>sentence_length_std</th>\n",
              "      <th>discourse_connective_count</th>\n",
              "      <th>vocabulary_richness</th>\n",
              "      <th>semantic_relevance</th>\n",
              "      <th>flesch_reading_ease</th>\n",
              "      <th>flesch_kincaid_grade</th>\n",
              "      <th>gunning_fog_index</th>\n",
              "      <th>smog_index</th>\n",
              "      <th>automated_readability_index</th>\n",
              "      <th>coleman_liau_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20716</td>\n",
              "      <td>8</td>\n",
              "      <td>A long time ago when I was in third grade I h...</td>\n",
              "      <td>18.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.002410</td>\n",
              "      <td>13</td>\n",
              "      <td>0.520505</td>\n",
              "      <td>0.707057</td>\n",
              "      <td>88.87</td>\n",
              "      <td>4.9</td>\n",
              "      <td>6.90</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.1</td>\n",
              "      <td>5.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20717</td>\n",
              "      <td>8</td>\n",
              "      <td>Softball has to be one of the single most gre...</td>\n",
              "      <td>21.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>11.949837</td>\n",
              "      <td>16</td>\n",
              "      <td>0.635593</td>\n",
              "      <td>0.777121</td>\n",
              "      <td>78.93</td>\n",
              "      <td>8.7</td>\n",
              "      <td>11.37</td>\n",
              "      <td>8.9</td>\n",
              "      <td>10.8</td>\n",
              "      <td>6.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20718</td>\n",
              "      <td>8</td>\n",
              "      <td>Some people like making people laugh, I love ...</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>11.317015</td>\n",
              "      <td>16</td>\n",
              "      <td>0.578164</td>\n",
              "      <td>0.795551</td>\n",
              "      <td>74.83</td>\n",
              "      <td>8.2</td>\n",
              "      <td>9.62</td>\n",
              "      <td>8.5</td>\n",
              "      <td>9.1</td>\n",
              "      <td>6.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20719</td>\n",
              "      <td>8</td>\n",
              "      <td>\"LAUGHTER\"  @CAPS1 I hang out with my friends...</td>\n",
              "      <td>12.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>17.686580</td>\n",
              "      <td>14</td>\n",
              "      <td>0.595070</td>\n",
              "      <td>0.737897</td>\n",
              "      <td>81.46</td>\n",
              "      <td>7.7</td>\n",
              "      <td>9.68</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>4.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20721</td>\n",
              "      <td>8</td>\n",
              "      <td>Well ima tell a story about the time i got @CA...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.722998</td>\n",
              "      <td>17</td>\n",
              "      <td>0.522388</td>\n",
              "      <td>0.625690</td>\n",
              "      <td>88.60</td>\n",
              "      <td>7.1</td>\n",
              "      <td>9.98</td>\n",
              "      <td>4.2</td>\n",
              "      <td>7.7</td>\n",
              "      <td>3.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>21626</td>\n",
              "      <td>8</td>\n",
              "      <td>In most stories mothers and daughters are eit...</td>\n",
              "      <td>17.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>17.869146</td>\n",
              "      <td>19</td>\n",
              "      <td>0.627072</td>\n",
              "      <td>0.794858</td>\n",
              "      <td>65.09</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.56</td>\n",
              "      <td>10.3</td>\n",
              "      <td>14.4</td>\n",
              "      <td>7.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>719</th>\n",
              "      <td>21628</td>\n",
              "      <td>8</td>\n",
              "      <td>I never understood the meaning laughter is th...</td>\n",
              "      <td>15.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.989607</td>\n",
              "      <td>7</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.791210</td>\n",
              "      <td>91.11</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.97</td>\n",
              "      <td>7.1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>4.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720</th>\n",
              "      <td>21629</td>\n",
              "      <td>8</td>\n",
              "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
              "      <td>20.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>17.083961</td>\n",
              "      <td>17</td>\n",
              "      <td>0.745509</td>\n",
              "      <td>0.766729</td>\n",
              "      <td>69.11</td>\n",
              "      <td>8.3</td>\n",
              "      <td>9.46</td>\n",
              "      <td>9.7</td>\n",
              "      <td>9.9</td>\n",
              "      <td>8.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>721</th>\n",
              "      <td>21630</td>\n",
              "      <td>8</td>\n",
              "      <td>Trippin' on fen...</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8.045972</td>\n",
              "      <td>21</td>\n",
              "      <td>0.663793</td>\n",
              "      <td>0.819285</td>\n",
              "      <td>81.83</td>\n",
              "      <td>5.5</td>\n",
              "      <td>7.41</td>\n",
              "      <td>8.5</td>\n",
              "      <td>6.8</td>\n",
              "      <td>6.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>722</th>\n",
              "      <td>21633</td>\n",
              "      <td>8</td>\n",
              "      <td>Many people believe that laughter can improve...</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>6.097503</td>\n",
              "      <td>9</td>\n",
              "      <td>0.707547</td>\n",
              "      <td>0.863376</td>\n",
              "      <td>72.05</td>\n",
              "      <td>7.2</td>\n",
              "      <td>8.67</td>\n",
              "      <td>9.9</td>\n",
              "      <td>7.4</td>\n",
              "      <td>7.07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>723 rows × 34 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c3e726a-f167-446e-be3f-72110eebfc20')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7c3e726a-f167-446e-be3f-72110eebfc20 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7c3e726a-f167-446e-be3f-72110eebfc20');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6be1349a-2058-414b-b279-7715fd5ef1d6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6be1349a-2058-414b-b279-7715fd5ef1d6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6be1349a-2058-414b-b279-7715fd5ef1d6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_138d11be-7282-4a6c-99af-d9ae2f91b9f6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_with_features')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_138d11be-7282-4a6c-99af-d9ae2f91b9f6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_with_features');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_with_features"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AhryfUduan8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_features.to_csv(\"df_with_features_set_8.csv\")"
      ],
      "metadata": {
        "id": "YTluMWmFY0jC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jfeatures = df_with_features[[\"essay\", \"num_grammatical_errors\", \"adjacent_sentence_similarity\",\"lexical_repetition_ratio\",\n",
        "             \"unique_lemmas_count\", \"pronoun_count\", \"avg_sentence_length\", \"discourse_connective_count\",\n",
        "             \"vocabulary_richness\", \"semantic_relevance\", \"flesch_reading_ease\", \"flesch_kincaid_grade\",\n",
        "             \"gunning_fog_index\", \"smog_index\", \"automated_readability_index\", \"coleman_liau_index\"\n",
        "             ]]\n",
        "\n",
        "scores = df_with_features[[ \"rater1_trait1\", \"rater1_trait2\", \"rater1_trait3\", \"rater1_trait4\",\n",
        "              \"rater2_trait1\", \"rater2_trait2\", \"rater2_trait3\", \"rater2_trait4\",\n",
        "              \"domain1_score\"]]\n",
        "features, scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jGwErsq0STu",
        "outputId": "8d9e7434-f3eb-4762-f92e-8c625ced0bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                                  essay  \\\n",
              " 0     Patience is when your waiting .I was patience ...   \n",
              " 1     I am not a patience person, like I can’t sit i...   \n",
              " 2     One day I was at basketball practice and I was...   \n",
              " 3     I going to write about a time when I went to t...   \n",
              " 4     It can be very hard for somebody to be patient...   \n",
              " ...                                                 ...   \n",
              " 1564  One time I was getting a cool @CAPS1 game it w...   \n",
              " 1565  A patent person in my life is my mom. Aicason ...   \n",
              " 1566  A time when someone else I know was patient wa...   \n",
              " 1567  I hate weddings. I love when people get marrie...   \n",
              " 1568  A few weeks ago, we had a garage sale and a mo...   \n",
              " \n",
              "       num_grammatical_errors  adjacent_sentence_similarity  \\\n",
              " 0                         20                      0.723575   \n",
              " 1                         10                      0.614597   \n",
              " 2                         23                      0.769198   \n",
              " 3                          8                      0.582397   \n",
              " 4                          3                      0.735146   \n",
              " ...                      ...                           ...   \n",
              " 1564                      10                      0.588245   \n",
              " 1565                       8                      0.779334   \n",
              " 1566                       5                      0.675659   \n",
              " 1567                      11                      0.604064   \n",
              " 1568                       3                      0.709756   \n",
              " \n",
              "       lexical_repetition_ratio  unique_lemmas_count  pronoun_count  \\\n",
              " 0                     0.439024                   28             10   \n",
              " 1                     0.500000                   28             12   \n",
              " 2                     0.446154                   48             22   \n",
              " 3                     0.487805                   56             40   \n",
              " 4                     0.574468                   29             25   \n",
              " ...                        ...                  ...            ...   \n",
              " 1564                  0.233333                   26             13   \n",
              " 1565                  0.423913                   69             39   \n",
              " 1566                  0.475410                   42             26   \n",
              " 1567                  0.515152                   89             43   \n",
              " 1568                  0.589286                   32             25   \n",
              " \n",
              "       avg_sentence_length  discourse_connective_count  vocabulary_richness  \\\n",
              " 0               24.750000                           5             0.647059   \n",
              " 1               20.400000                           2             0.738095   \n",
              " 2               33.800000                           7             0.764706   \n",
              " 3               18.785714                           9             0.771739   \n",
              " 4               14.583333                          11             0.596774   \n",
              " ...                   ...                         ...                  ...   \n",
              " 1564            11.285714                           0             0.875000   \n",
              " 1565            26.333333                          12             0.752212   \n",
              " 1566            15.416667                           5             0.777778   \n",
              " 1567             9.800000                           8             0.794393   \n",
              " 1568            18.200000                           3             0.609375   \n",
              " \n",
              "       semantic_relevance  flesch_reading_ease  flesch_kincaid_grade  \\\n",
              " 0               0.817931                88.53                   2.9   \n",
              " 1               0.733223                73.55                  10.8   \n",
              " 2               0.740397                66.44                  13.5   \n",
              " 3               0.836043                88.36                   5.1   \n",
              " 4               0.850627                84.07                   4.7   \n",
              " ...                  ...                  ...                   ...   \n",
              " 1564            0.687756               103.52                   1.3   \n",
              " 1565            0.779246                71.68                   9.4   \n",
              " 1566            0.806946                83.86                   4.7   \n",
              " 1567            0.694650                87.62                   3.3   \n",
              " 1568            0.771673                94.90                   4.6   \n",
              " \n",
              "       gunning_fog_index  smog_index  automated_readability_index  \\\n",
              " 0                  3.28         4.9                          3.5   \n",
              " 1                 12.95         8.8                         12.5   \n",
              " 2                 15.84        10.7                         16.5   \n",
              " 3                  7.60         7.3                          6.6   \n",
              " 4                  5.83         7.5                          5.4   \n",
              " ...                 ...         ...                          ...   \n",
              " 1564               4.04         3.1                          0.1   \n",
              " 1565              11.89        10.3                         11.0   \n",
              " 1566               6.32         8.4                          4.8   \n",
              " 1567               5.16         7.2                          4.2   \n",
              " 1568               7.44         3.1                          4.0   \n",
              " \n",
              "       coleman_liau_index  \n",
              " 0                   5.24  \n",
              " 1                   5.29  \n",
              " 2                   5.87  \n",
              " 3                   5.33  \n",
              " 4                   6.13  \n",
              " ...                  ...  \n",
              " 1564                0.79  \n",
              " 1565                7.32  \n",
              " 1566                5.44  \n",
              " 1567                4.32  \n",
              " 1568                2.09  \n",
              " \n",
              " [1569 rows x 16 columns],\n",
              "       rater1_trait1  rater1_trait2  rater1_trait3  rater1_trait4  \\\n",
              " 0               1.0            2.0            2.0            3.0   \n",
              " 1               1.0            1.0            2.0            2.0   \n",
              " 2               1.0            2.0            2.0            2.0   \n",
              " 3               2.0            2.0            2.0            2.0   \n",
              " 4               1.0            2.0            2.0            2.0   \n",
              " ...             ...            ...            ...            ...   \n",
              " 1564            2.0            2.0            1.0            1.0   \n",
              " 1565            2.0            2.0            2.0            3.0   \n",
              " 1566            3.0            3.0            2.0            3.0   \n",
              " 1567            3.0            3.0            3.0            3.0   \n",
              " 1568            2.0            1.0            2.0            2.0   \n",
              " \n",
              "       rater2_trait1  rater2_trait2  rater2_trait3  rater2_trait4  \\\n",
              " 0               1.0            2.0            2.0            2.0   \n",
              " 1               2.0            2.0            2.0            1.0   \n",
              " 2               2.0            2.0            2.0            2.0   \n",
              " 3               2.0            2.0            2.0            3.0   \n",
              " 4               1.0            2.0            1.0            2.0   \n",
              " ...             ...            ...            ...            ...   \n",
              " 1564            1.0            2.0            2.0            1.0   \n",
              " 1565            0.0            2.0            2.0            3.0   \n",
              " 1566            2.0            2.0            2.0            2.0   \n",
              " 1567            2.0            3.0            2.0            3.0   \n",
              " 1568            2.0            2.0            2.0            2.0   \n",
              " \n",
              "       domain1_score  \n",
              " 0              15.0  \n",
              " 1              13.0  \n",
              " 2              15.0  \n",
              " 3              17.0  \n",
              " 4              13.0  \n",
              " ...             ...  \n",
              " 1564           12.0  \n",
              " 1565           16.0  \n",
              " 1566           19.0  \n",
              " 1567           22.0  \n",
              " 1568           15.0  \n",
              " \n",
              " [1569 rows x 9 columns])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n"
      ],
      "metadata": {
        "id": "fTF0Ztcj8ArF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, test_features, train_scores, test_scores = train_test_split(features, scores, test_size=0.2, random_state=42)\n",
        "len(train_features), len(test_features), len(train_scores), len(test_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S9FU69Wy9RN",
        "outputId": "9c08979c-ee6d-4c9d-9950-f213b18be499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1255, 314, 1255, 314)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_essays = train_features[\"essay\"]\n",
        "test_essays = test_features[\"essay\"]\n",
        "train_features_extract = train_features.drop(\"essay\", axis=1)\n",
        "test_features_extract = test_features.drop(\"essay\", axis=1)"
      ],
      "metadata": {
        "id": "MWOWu7Kn8h8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_features_train = scaler.fit_transform(train_features_extract)\n",
        "scaled_features_test = scaler.transform(test_features_extract)"
      ],
      "metadata": {
        "id": "9uU4IFfM8_sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_features_train_df = pd.DataFrame(scaled_features_train, columns=train_features_extract.columns)\n",
        "scaled_features_test_df = pd.DataFrame(scaled_features_test, columns=test_features_extract.columns)\n"
      ],
      "metadata": {
        "id": "44w2Bbrn9Dh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "yqjqjrlFlke1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26924f15-b732-4f12-fbcc-adfcad20ed7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "batch_size = 32\n",
        "class EssayDataset(Dataset):\n",
        "    def __init__(self, essays, scores, features, tokenizer, max_length=512):\n",
        "        self.essays = essays.to_list()\n",
        "        self.r1_scores = scores[['rater1_trait1', 'rater1_trait2', 'rater1_trait3', 'rater1_trait4']].values.tolist()\n",
        "        self.r2_scores = scores[['rater2_trait1', 'rater2_trait2', 'rater2_trait3', 'rater2_trait4']].values.tolist()\n",
        "        self.overall_scores = scores[['domain1_score']].values.tolist()\n",
        "        self.features = features.values.tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.essays)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        essay = self.essays[idx]\n",
        "        r1_score = self.r1_scores[idx]\n",
        "        r2_score = self.r2_scores[idx]\n",
        "        overall_score = self.overall_scores[idx]\n",
        "        feature = self.features[idx]\n",
        "\n",
        "        tokens = self.tokenizer(essay, padding='max_length', truncation=True, max_length=self.max_length, return_tensors='pt')\n",
        "        return {'input_ids': tokens['input_ids'].squeeze().to(device),\n",
        "                'attention_mask': tokens['attention_mask'].squeeze().to(device),\n",
        "                'r1_scores': torch.tensor(r1_score, dtype=torch.float).to(device),\n",
        "                'r2_scores': torch.tensor(r2_score, dtype=torch.float).to(device),\n",
        "                'overall_score': torch.tensor(overall_score, dtype=torch.float).to(device),\n",
        "                'features': torch.tensor(feature, dtype=torch.float).to(device)}\n",
        "\n",
        "# Example usage:\n",
        "train_dataset = EssayDataset(train_essays,\n",
        "                             train_scores,\n",
        "                             scaled_features_train_df,\n",
        "                             tokenizer)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "id": "vUNfl02E22mA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "b3d52fcc-096e-46bf-f2a4-f3d9076a72cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_essays' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-829966e6fbc7>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Example usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m train_dataset = EssayDataset(train_essays,\n\u001b[0m\u001b[1;32m     34\u001b[0m                              \u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                              \u001b[0mscaled_features_train_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_essays' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# class EssayDataset(Dataset):\n",
        "#     def __init__(self, essays, scores, features, tokenizer, max_length=512):\n",
        "#         self.essays = essays.to_list()\n",
        "#         self.scores = scores.to_list()\n",
        "#         self.features = features.to_dict('records')  # Convert DataFrame to list of dictionaries\n",
        "#         self.tokenizer = tokenizer\n",
        "#         self.max_length = max_length\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.essays)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         essay = self.essays[idx]\n",
        "#         score = self.scores[idx]\n",
        "#         feature_dict = self.features[idx]\n",
        "\n",
        "#         tokens = self.tokenizer(essay, padding='max_length', truncation=True, max_length=self.max_length, return_tensors='pt')\n",
        "\n",
        "#         # Extract features and convert to tensor\n",
        "#         feature_tensors = {k: torch.tensor(v, dtype=torch.float).to(device) for k, v in feature_dict.items()}\n",
        "\n",
        "#         return {\n",
        "#             'input_ids': tokens['input_ids'].squeeze().to(device),\n",
        "#             'attention_mask': tokens['attention_mask'].squeeze().to(device),\n",
        "#             'score': torch.tensor(score, dtype=torch.float).to(device),\n",
        "#             **feature_tensors  # Include the features in the output\n",
        "#         }\n",
        "\n",
        "# # Example usage:\n",
        "# # Assuming `features_df` is your DataFrame containing the features\n",
        "# train_dataset = EssayDataset(train_essays, train_scores, features_df, tokenizer)\n",
        "# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "id": "nRVoLg1BqOUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class BertForRegression(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.bert = BertModel(config)\n",
        "        input_dim = config.hidden_size + 15\n",
        "        self.r1_trait1_head = nn.Linear(input_dim, 1)\n",
        "        self.r1_trait2_head = nn.Linear(input_dim, 1)\n",
        "        self.r1_trait3_head = nn.Linear(input_dim, 1)\n",
        "        self.r1_trait4_head = nn.Linear(input_dim, 1)\n",
        "\n",
        "        self.r2_trait1_head = nn.Linear(input_dim, 1)\n",
        "        self.r2_trait2_head = nn.Linear(input_dim, 1)\n",
        "        self.r2_trait3_head = nn.Linear(input_dim, 1)\n",
        "        self.r2_trait4_head = nn.Linear(input_dim, 1)\n",
        "        self.overall_head = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, features = None):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "        # Concatenate features to the CLS output\n",
        "        if features is not None:\n",
        "            # Ensure features are of the right type and on the correct device\n",
        "            features = features.to(cls_output.device, dtype=cls_output.dtype)\n",
        "            combined_output = torch.cat((cls_output, features), dim=1)  # Concatenate along the feature dimension\n",
        "        else:\n",
        "            combined_output = cls_output  # If no features are provided, use only the CLS output\n",
        "        r1_trait1 = self.r1_trait1_head(combined_output)\n",
        "        r1_trait2 = self.r1_trait2_head(combined_output)\n",
        "        r1_trait3 = self.r1_trait3_head(combined_output)\n",
        "        r1_trait4 = self.r1_trait4_head(combined_output)\n",
        "\n",
        "        r2_trait1 = self.r2_trait1_head(combined_output)\n",
        "        r2_trait2 = self.r2_trait2_head(combined_output)\n",
        "        r2_trait3 = self.r2_trait3_head(combined_output)\n",
        "        r2_trait4 = self.r2_trait4_head(combined_output)\n",
        "        overall = self.overall_head(combined_output)\n",
        "        return r1_trait1, r1_trait2, r1_trait3, r1_trait4, r2_trait1, r2_trait2, r2_trait3, r2_trait4, overall"
      ],
      "metadata": {
        "id": "R04apT0oy5Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertConfig\n",
        "import torch.optim as optim\n",
        "\n",
        "config = BertConfig.from_pretrained('bert-base-uncased')\n",
        "model = BertForRegression.from_pretrained('bert-base-uncased', config=config).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
        "criterion = torch.nn.MSELoss()"
      ],
      "metadata": {
        "id": "Ogzga4SZzWV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch in train_dataloader:\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        r1_scores = batch['r1_scores']\n",
        "        r2_scores = batch['r2_scores']\n",
        "        overall_scores = batch[\"overall_score\"]\n",
        "        features = batch[\"features\"]\n",
        "\n",
        "\n",
        "        targets = torch.cat((r1_scores, r2_scores, overall_scores), dim=1)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, features=features)\n",
        "\n",
        "        model_outputs = torch.cat(outputs, dim=1)\n",
        "\n",
        "        loss = criterion(model_outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "id": "5YcUjgN1zcf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = EssayDataset(test_essays, test_scores, scaled_features_test_df, tokenizer)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=4)"
      ],
      "metadata": {
        "id": "1N4vOJUJ23aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "import numpy as np\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize variables for evaluation\n",
        "all_predictions = []\n",
        "all_targets = []\n",
        "eval_loss = 0\n",
        "\n",
        "# Disable gradient calculations for testing\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        # Extract inputs and move to the appropriate device\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        r1_scores = batch['r1_scores'].to(device)\n",
        "        r2_scores = batch['r2_scores'].to(device)\n",
        "        overall_scores = batch[\"overall_score\"].to(device)\n",
        "        features = batch[\"features\"].to(device)\n",
        "\n",
        "        # Combine targets into a single tensor\n",
        "        targets = torch.cat((r1_scores, r2_scores, overall_scores), dim=1)\n",
        "\n",
        "        # Get predictions from the model\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, features=features)\n",
        "\n",
        "        # Concatenate the outputs for the three traits and the overall score\n",
        "        model_outputs = torch.cat(outputs, dim=1)\n",
        "\n",
        "        # Calculate the evaluation loss for this batch\n",
        "        eval_loss += criterion(model_outputs, targets).item()\n",
        "\n",
        "        # Collect predictions and actual targets for further evaluation\n",
        "        all_predictions.extend(model_outputs[:, -1].cpu().numpy())  # Assuming the last column is the overall score\n",
        "        all_targets.extend(overall_scores.cpu().numpy())\n",
        "\n",
        "# Calculate the average evaluation loss over all batches\n",
        "avg_eval_loss = eval_loss / len(test_dataloader)\n",
        "print(f'Validation Loss: {avg_eval_loss}')\n",
        "\n",
        "# Convert predictions and targets to numpy arrays for QWK calculation\n",
        "all_predictions = np.array(all_predictions).flatten()\n",
        "all_targets = np.array(all_targets).flatten()\n",
        "\n",
        "# Round predictions to the nearest integer for QWK\n",
        "all_predictions_rounded = np.round(all_predictions)\n",
        "\n",
        "# Calculate QWK for the overall score\n",
        "qwk_overall = cohen_kappa_score(all_targets, all_predictions_rounded, weights='quadratic')\n",
        "print(f'QWK Overall: {qwk_overall}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlOj90c4z0Cd",
        "outputId": "7df48f7d-8f8c-43fc-95a0-66a1ff2b44cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.9752898716096636\n",
            "QWK Overall: 0.8213449518268734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_with_handcrafted_feature.pt')\n",
        "# When loading\n",
        "# model.load_state_dict(torch.load('model_11.pt', map_location=device))\n"
      ],
      "metadata": {
        "id": "_wEGMwD83CX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "index = 0\n",
        "essay = test_essays.iloc[index]\n",
        "score = test_scores.iloc[index]\n",
        "feature = scaled_features_test_df.iloc[index]\n",
        "def predict_essay(essay, model, tokenizer, device, features):\n",
        "    model.eval()\n",
        "    inputs = tokenizer(essay, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "    feature_tensor = torch.tensor(features.values, dtype=torch.float32)\n",
        "    features = feature_tensor.unsqueeze(0).to(device, dtype=torch.float)\n",
        "    print(features.shape)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        r1_trait1, r1_trait2, r1_trait3, r1_trait4, r2_trait1, r2_trait2, r2_trait3, r2_trait4, overall = model(input_ids=input_ids, attention_mask=attention_mask, features=features)\n",
        "        predicted_r1_trait1 = r1_trait1.squeeze().cpu().numpy()  # Assuming single output per trait\n",
        "        predicted_r1_trait2 = r1_trait2.squeeze().cpu().numpy()\n",
        "        predicted_r1_trait3 = r1_trait3.squeeze().cpu().numpy()\n",
        "        predicted_r1_trait4 = r1_trait4.squeeze().cpu().numpy()\n",
        "\n",
        "        predicted_r2_trait1 = r2_trait1.squeeze().cpu().numpy()  # Assuming single output per trait\n",
        "        predicted_r2_trait2 = r2_trait2.squeeze().cpu().numpy()\n",
        "        predicted_r2_trait3 = r2_trait3.squeeze().cpu().numpy()\n",
        "        predicted_r2_trait4 = r2_trait4.squeeze().cpu().numpy()\n",
        "\n",
        "        predicted_overall = overall.squeeze().cpu().numpy()\n",
        "\n",
        "\n",
        "\n",
        "    return predicted_r1_trait1, predicted_r1_trait2, predicted_r1_trait3, predicted_r1_trait4, predicted_r2_trait1,predicted_r2_trait2, predicted_r2_trait3,  predicted_r2_trait4, predicted_overall\n",
        "predicted_r1_trait1, predicted_r1_trait2, predicted_r1_trait3, predicted_r1_trait4, predicted_r2_trait1,predicted_r2_trait2, predicted_r2_trait3,  predicted_r2_trait4, predicted_overall  = predict_essay(essay, model, tokenizer, device, feature)\n",
        "print(test_essays.iloc[index])\n",
        "print(\"predicted_r1: ideas, organization, style, convention \\n \", predicted_r1_trait1, predicted_r1_trait2, predicted_r1_trait3, predicted_r1_trait4)\n",
        "print(\"predicted_r2: ideas, organization, style, convention  \\n \", predicted_r2_trait1,predicted_r2_trait2, predicted_r2_trait3,  predicted_r2_trait4)\n",
        "print(\"predicted_r3: overall score \\n \", predicted_overall)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"actual: \", score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3kPEc4V3PIu",
        "outputId": "e6632c2b-117b-46b1-d704-c4210db460e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 15])\n",
            "My at saying your patient is. Your patient when you wait in line for something is being patient. Waiting your turn is being patience one time I was patient by waiting on the bench to play but I didn`t get to play until the fourth queiter with @NUM1 to go but you know what I did had patience. A lot of people have patient but some people just don`t have manner when they just don`t care and start the yell and screaming. Like popstars a lot of singers popstar and other famous people think they can cut in front of any one cause their rich but it they wern`t rich they would cut pop stars and movie stars just need to have patient. Am not saying all popstars and movie stars don`t have patient when they were little they never act like that.\n",
            "predicted_r1: ideas, organization, style, convention \n",
            "  0.53180027 1.4078546 2.1636386 1.9615777\n",
            "predicted_r2: ideas, organization, style, convention  \n",
            "  0.9017922 1.6942227 1.8754803 2.0368257\n",
            "predicted_r3: overall score \n",
            "  12.904104\n",
            "\n",
            "\n",
            "actual:  rater1_trait1     2.0\n",
            "rater1_trait2     2.0\n",
            "rater1_trait3     2.0\n",
            "rater1_trait4     2.0\n",
            "rater2_trait1     0.0\n",
            "rater2_trait2     1.0\n",
            "rater2_trait3     1.0\n",
            "rater2_trait4     2.0\n",
            "domain1_score    12.0\n",
            "Name: 1412, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  essay = test_essays.iloc[i]\n",
        "  score = test_scores.iloc[i]\n",
        "  predicted = predict_essay(essay, model, tokenizer, device)\n",
        "  print(test_essays.iloc[i])\n",
        "  print(\"predicted: \", predicted, \"actual: \", score, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "5uOZ-HPO4OzN",
        "outputId": "db825039-12cd-4122-c5f3-02b87676e455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "predict_essay() missing 1 required positional argument: 'features'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-2921cdb09af3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0messay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_essays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_essay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0messay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_essays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predicted: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"actual: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: predict_essay() missing 1 required positional argument: 'features'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qUdpZjDB5TB1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}